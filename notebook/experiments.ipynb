{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28327201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all_ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273bada1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mahmoudmohamed/Library/Mobile Documents/com~apple~CloudDocs/Project/llmops_industry_ready_projects/document_portal/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "OPENAI KEY Exists\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"OPENAI KEY Exists\")\n",
    "else:\n",
    "    print(\"NO OPENAI KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4676b694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\",temperature=0)\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "result = model.invoke(\"captial of france)\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbeb484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(len(embedding.embed_query(\"hello World!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13b665",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7747e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader , DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90038fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8655308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF PATH: /Users/mahmoudmohamed/Library/Mobile Documents/com~apple~CloudDocs/Project/llmops_industry_ready_projects/document_portal/notebook/data/rag.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_path = os.path.join(os.getcwd(),\"data\",\"rag.pdf\")\n",
    "print(f\"PDF PATH: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1cfe667",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(os.path.join(os.getcwd(),\"data\"),glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4985c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900\n"
     ]
    }
   ],
   "source": [
    "doc[0].page_content[:500]\n",
    "doc[0].metadata\n",
    "print(len(embedding.embed_documents(doc[0].page_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e196fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9972f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500,\n",
    "                                        chunk_overlap=200,\n",
    "                                        length_function=len,\n",
    "                                        separators=[\"\\n\\n\",\"\\n\",\".\",\" \",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6022eb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = splitter.split_documents(doc)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61afe4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319.68\n"
     ]
    }
   ],
   "source": [
    "len_chunks = []\n",
    "for chunk in chunks: \n",
    "    text_len = len(chunk.page_content)\n",
    "    len_chunks.append(text_len)\n",
    "\n",
    "print((round(sum(len_chunks)/len(chunks),2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90e11468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.21',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2021-04-13T00:48:38+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2021-04-13T00:48:38+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': '/Users/mahmoudmohamed/Library/Mobile Documents/com~apple~CloudDocs/Project/llmops_industry_ready_projects/document_portal/notebook/data/rag.pdf',\n",
       " 'total_pages': 19,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd05a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d29531",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss = FAISS(docstore=\"./faiss_index\",embedding_function=embedding,\n",
    "              index=None,index_to_docstore_id=None)\n",
    "vector_store = faiss.from_documents(chunks,embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479a7118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RAG research paradigm is continuously evolving, and\n",
      "we categorize it into three stages: Naive RA\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "sizes RAGâ€™s significant advancement in enhancing the capa-\n",
      "bilities of LLMs by integrating parameter\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "becoming prevalent, supporting both sequential processing and\n",
      "integrated end-to-end training across \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "16\n",
      "Fig. 6. Summary of RAG ecosystem\n",
      "initial learning curve. 3) Specialization - optimizing RAG to\n",
      "be\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = vector_store.similarity_search(\"what is rag?\",k=4)\n",
    "for result in result:\n",
    "    print(result.page_content[:100])\n",
    "    print(\"-----\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3112abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":6}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "127dcd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Answer the question based on the context below. \n",
    "If the answer is not contained within the text, \n",
    "respond with \"I don't know\".\n",
    "\n",
    "context: {context}\n",
    "\n",
    "question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "174b2bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG, or Retrieval-Augmented Generation, is a research paradigm that integrates retrieval techniques with generative language models to enhance their capabilities. It is categorized into three stages: Naive RAG, Advanced RAG, and Modular RAG. RAG models are designed to improve performance in various tasks by leveraging external knowledge bases and multimodal data, including text, images, audio, and video. The RAG framework focuses on the core components of \"Retrieval,\" \"Generation,\" and \"Augmentation,\" and aims to optimize the performance of language models across diverse application scenarios.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return\"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "rag_chain = ({\"context\":retriever | format_docs , \"question\": RunnablePassthrough()\n",
    "              }| prompt | model | StrOutputParser())\n",
    "result = rag_chain.invoke(\"what is RAG?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e30f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec2981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055d9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213a322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c90a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09891fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f172184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcab79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed94f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897331b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ac37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a4605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e52027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2133754b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3afcae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b716b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96e907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22cbc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56d21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812ba75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc327a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f133fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3e6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
